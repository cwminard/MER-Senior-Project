{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7636b468",
   "metadata": {},
   "source": [
    "capture audio and video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88853729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording audio\n",
      "* done recording audio\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def record_video_and_audio():\n",
    "    cap = cv.VideoCapture(0)\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv.VideoWriter('C:\\\\Users\\\\chels\\\\Desktop\\\\COSC490-MER\\\\outputs\\\\video\\\\output.mp4', fourcc, 20.0, (640, 480))\n",
    "\n",
    "    CHUNK = 4096  # Increased chunk size for smoother audio\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    WAVE_OUTPUT_FILENAME = \"C:\\\\Users\\\\chels\\\\Desktop\\\\COSC490-MER\\\\outputs\\\\audio\\\\output.wav\"\n",
    "    frames = []\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = None\n",
    "\n",
    "    audio_started = False\n",
    "    audio_running = True\n",
    "\n",
    "    def audio_record():\n",
    "        nonlocal stream, frames, audio_running\n",
    "        stream = p.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "        print(\"* recording audio\")\n",
    "        while audio_running:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "\n",
    "    audio_thread = threading.Thread(target=audio_record)\n",
    "    audio_thread.start()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        out.write(frame)\n",
    "        cv.imshow('frame', frame)\n",
    "\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Cleanup video\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # Cleanup audio\n",
    "    audio_running = False\n",
    "    audio_thread.join()\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    print(\"* done recording audio\")\n",
    "record_video_and_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d4bb4",
   "metadata": {},
   "source": [
    "grab the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999172fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def transcribe_audio():\n",
    "  base_url = \"https://api.assemblyai.com\"\n",
    "\n",
    "  headers = {\n",
    "      \"authorization\": \"6a35340cac1c443e8e4bbc1d027a3ad5\"\n",
    "  }\n",
    "  with open(\"outputs/audio/output.wav\", \"rb\") as f:\n",
    "    response = requests.post(base_url + \"/v2/upload\",\n",
    "                            headers=headers,\n",
    "                            data=f)\n",
    "\n",
    "  audio_url = response.json()[\"upload_url\"]\n",
    "\n",
    "\n",
    "  data = {\n",
    "      \"audio_url\": audio_url,\n",
    "      \"speech_model\": \"universal\"\n",
    "  }\n",
    "\n",
    "  url = base_url + \"/v2/transcript\"\n",
    "  response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "  transcript_id = response.json()['id']\n",
    "  polling_endpoint = base_url + \"/v2/transcript/\" + transcript_id\n",
    "\n",
    "  while True:\n",
    "    transcription_result = requests.get(polling_endpoint, headers=headers).json()\n",
    "    transcript_text = transcription_result['text']\n",
    "\n",
    "    if transcription_result['status'] == 'completed':\n",
    "      print(\"Transcription completed.\")\n",
    "      return transcript_text\n",
    "      # with open(\"transcript.txt\", \"w\") as file:\n",
    "      #   file.write(transcript_text) # we don't necessarily need to write it into a file\n",
    "      # file.close()\n",
    "\n",
    "    elif transcription_result['status'] == 'error':\n",
    "      raise RuntimeError(f\"Transcription failed: {transcription_result['error']}\")\n",
    "\n",
    "    else:\n",
    "      time.sleep(3)\n",
    "text = transcribe_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8bf78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I feel really bad because today I accidentally bumped into somebody without saying excuse me, and I feel like they probably don't like me now because I didn't say excuse me to them. And I feel really bad, and I don't know what to do to resolve the situation. It's been weighing on my mind really heavily today because I kind of had a rough day, and I feel like that just made it a little bit worse, and I think that they probably don't like me now.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae605509",
   "metadata": {},
   "source": [
    "sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a611091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def tokens_to_text(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score\n",
    "\n",
    "def determine_sentiment(score):\n",
    "    if score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "score = analyzer.polarity_scores(text)\n",
    "sentiment = determine_sentiment(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70c238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47126c",
   "metadata": {},
   "source": [
    "video analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de457621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fer.fer import FER\n",
    "from fer.classes import Video\n",
    "import pandas as pd\n",
    "def analyze_video_emotions():\n",
    "    emotion_detector = FER(mtcnn=True)\n",
    "    video = Video(\"C:\\\\Users\\\\chels\\\\Desktop\\\\COSC490-MER\\\\outputs\\\\video\\\\output.mp4\")\n",
    "\n",
    "\n",
    "    emotions = video.analyze(emotion_detector, display=False, frequency=5)\n",
    "    df = pd.DataFrame(emotions)\n",
    "\n",
    "\n",
    "    stats = df.describe()\n",
    "    return stats.loc['mean'].nlargest(2).index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fer:20.00 fps, 877 frames, 43.85 seconds\n",
      "INFO:fer:Making directories at output\n",
      "INFO:fer:Async I/O enabled for frame saving\n",
      "176frames [00:30,  5.85frames/s]                     \n",
      "INFO:fer:Waiting for async I/O to complete...\n",
      "INFO:fer:Async I/O completed\n",
      "INFO:fer:Completed analysis: saved to output\\output_output.mp4\n",
      "INFO:fer:Starting to Zip\n",
      "INFO:fer:Compressing: 28%\n",
      "INFO:fer:Compressing: 56%\n",
      "INFO:fer:Compressing: 85%\n",
      "INFO:fer:Zip has finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotions = analyze_video_emotions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11507be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emotion1, emotion2 = emotions[0], emotions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c9bd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sad1', 'fear0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion1, emotion2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd7be6",
   "metadata": {},
   "source": [
    "therapyAI chatbot response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dc9d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you’re carrying a really heavy burden of self-doubt and worry right now, and it’s completely understandable why you feel so intensely bad. The fact that you’re experiencing this significant discomfort – this feeling of not saying ‘excuse me’ and then imagining the worst – speaks volumes about your inherent desire to be considerate and polite. \n",
      "\n",
      "Let's acknowledge that your anxiety is understandably amplified by a tough day, and that’s creating a feedback loop where you’re focusing on a single, relatively minor event and letting it magnify into something much more significant.  It’s incredibly common to do this, especially when we're already feeling vulnerable. \n",
      "\n",
      "What you’re feeling – this worry that someone dislikes you – isn’t necessarily based on reality. People are often far more forgiving than we give them credit for. More importantly, focusing solely on this one instance is preventing you from enjoying the rest of your day. \n",
      "\n",
      "Try this: Gently remind yourself that you made a small, unintentional mistake, and it’s okay.  Let go of the ‘what ifs’ and the imagined judgment.  Practice self-compassion; treat yourself with the same kindness and understanding you’d offer a friend in a similar situation. You've acknowledged your mistake, which is a positive step, and you can now shift your focus to moving forward.  Allow yourself to release this anxiety – it's a natural reaction, but it doesn’t define the interaction or your worth.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "response: ChatResponse = chat(model='gemma3', messages=[\n",
    "  {\n",
    "    'role': 'system',\n",
    "    'content': f'Based on the user\\'s two primary emotions {emotion1} and {emotion2} from the video analysis, and based on the sentiment of the text which is {sentiment}, generate a therapuetic, empathetic response to the user\\'s words. Avoid asking follow-up questions (if waranted), but rather provide advice as a therapist would. The user said: {text}'\n",
    "  }\n",
    "])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a20c65",
   "metadata": {},
   "source": [
    "final call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_video_and_audio() # record and capture the audio\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
